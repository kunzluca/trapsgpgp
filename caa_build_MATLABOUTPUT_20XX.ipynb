{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© 2024 Luca Kunz. Commercial use is subject to the terms of the source repository's license. All other commercial rights are reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge snapshots of TRAPS to yearly DataFrames\n",
    "==\n",
    "\n",
    "For every year of output data, load and concatenate the snapshot TRAP coordinate dataframes exported by the TRAPs MATLAB algorithm.  \n",
    "Create and export one pandas DataFrame for all TRAP occurences within one year.\n",
    "\n",
    "This simple file only serves for completeness while the merged output files are already available and TRAPs can be directly recomputed starting from the next script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the computation time for the entire script\n",
    "start_script_timer = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if script is running in jupyter lab\n",
    "if sys.argv[0].endswith(\"ipykernel_launcher.py\"):\n",
    "    # set the velocity product\n",
    "    vel_product_ID = 1\n",
    "    year_ID = 0\n",
    "    notebook_run = True\n",
    "    # save_fig = True\n",
    "    save_fig = False\n",
    "\n",
    "    \n",
    "# if script is running as python script\n",
    "else:\n",
    "    # read in product from bash\n",
    "    vel_product_ID = int(sys.argv[1])\n",
    "    # read in year from bash\n",
    "    year_ID = int(sys.argv[2])\n",
    "    notebook_run = False\n",
    "    save_fig = True\n",
    "\n",
    "\n",
    "vel_product_short = ['ENSRYS_24HM', 'MULTIOBS_24HI', 'MULTIOBS_24HM', 'SEALEVEL_24HI'][vel_product_ID]\n",
    "\n",
    "vel_product_long = ['CMEMS GLOBAL_REANALYSIS_PHY_001_031 ENSEMBLE MEAN (1/4°, 24HM)', \n",
    "                    'CMEMS MULTIOBS_GLO_PHY_REP_015_004 (1/4°, 24HI)', \n",
    "                    'CMEMS MULTIOBS_GLO_PHY_REP_015_004 (1/4°, 24HM)', \n",
    "                    'SEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046'][vel_product_ID]\n",
    "\n",
    "years = ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', \n",
    "         '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
    "\n",
    "year = years[year_ID]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths to matlab output csv files\n",
    "xTC_csvpath = 'export_matlab/xTC/' + vel_product_short + '/' + year + '/'\n",
    "yTC_csvpath = 'export_matlab/yTC/' + vel_product_short + '/' + year + '/'\n",
    "pxt_csvpath = 'export_matlab/pxt/' + vel_product_short + '/' + year + '/'\n",
    "pyt_csvpath = 'export_matlab/pyt/' + vel_product_short + '/' + year + '/'\n",
    "s1TC_csvpath = 'export_matlab/s1TC/' + vel_product_short + '/' + year + '/'\n",
    "\n",
    "# collect all csv files from the given directories, fn for filename\n",
    "xTC_filenames = [fn for fn in os.listdir(xTC_csvpath) if fn.endswith('.csv')]\n",
    "yTC_filenames = [fn for fn in os.listdir(yTC_csvpath) if fn.endswith('.csv')]\n",
    "pxt_filenames = [fn for fn in os.listdir(pxt_csvpath) if fn.endswith('.csv')]\n",
    "pyt_filenames = [fn for fn in os.listdir(pyt_csvpath) if fn.endswith('.csv')]\n",
    "s1TC_filenames = [fn for fn in os.listdir(s1TC_csvpath) if fn.endswith('.csv')]\n",
    "\n",
    "# sort the unordered lists\n",
    "xTC_filenames.sort()\n",
    "yTC_filenames.sort()\n",
    "pxt_filenames.sort()\n",
    "pyt_filenames.sort()\n",
    "s1TC_filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print check\n",
    "#xTC_filenames\n",
    "#yTC_filenames\n",
    "#pxt_filenames\n",
    "#pyt_filenames\n",
    "#s1TC_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the timestamps from the filenames, call them timestrings since these are no datetime objects\n",
    "xTC_timestrings = [(fn.split('_')[3]).split('.')[0] for fn in xTC_filenames]\n",
    "yTC_timestrings = [(fn.split('_')[3]).split('.')[0] for fn in yTC_filenames]\n",
    "pxt_timestrings = [(fn.split('_')[3]).split('.')[0] for fn in pxt_filenames]\n",
    "pyt_timestrings = [(fn.split('_')[3]).split('.')[0] for fn in pyt_filenames]\n",
    "s1TC_timestrings = [(fn.split('_')[3]).split('.')[0] for fn in s1TC_filenames]\n",
    "\n",
    "# assert that for all components data is given for the same timestamps\n",
    "assert xTC_timestrings==yTC_timestrings==pxt_timestrings==pyt_timestrings==s1TC_timestrings, 'mismatching timestamps'\n",
    "\n",
    "# define one array for all timestamps\n",
    "timestrings = xTC_timestrings\n",
    "\n",
    "# assert that timestrings are unique and in order\n",
    "assert np.all(timestrings==np.unique(timestrings)), 'unordered or duplicate timestamps'\n",
    "\n",
    "# get the prefix of the csv files excluding the timestamp\n",
    "xTC_prefix = xTC_filenames[0][:-16]\n",
    "yTC_prefix = yTC_filenames[0][:-16]\n",
    "pxt_prefix = pxt_filenames[0][:-16]\n",
    "pyt_prefix = pyt_filenames[0][:-16]\n",
    "s1TC_prefix = s1TC_filenames[0][:-16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save memory\n",
    "del xTC_timestrings, yTC_timestrings, pxt_timestrings, pyt_timestrings, s1TC_timestrings\n",
    "del xTC_filenames, yTC_filenames, pxt_filenames, pyt_filenames, s1TC_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & concatenate DataFrames\n",
    "\n",
    "Read the data from the respective csv files and put it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timer = time.perf_counter()\n",
    "\n",
    "# initialise the main DataFrames upon which to concat in the following loop\n",
    "pd_xTC_df = pd.DataFrame()\n",
    "pd_yTC_df = pd.DataFrame()\n",
    "pd_pxt_df = pd.DataFrame()\n",
    "pd_pyt_df = pd.DataFrame()\n",
    "pd_s1TC_df = pd.DataFrame()\n",
    "\n",
    "for timestring in timestrings:\n",
    "\n",
    "    # cdf for current DataFrame\n",
    "    # xTC: x-component trap cores, yTC: y-component trap cores - vector\n",
    "    pd_xTC_cdf = pd.read_csv(xTC_csvpath + xTC_prefix + timestring + '.csv', header=None)\n",
    "    pd_yTC_cdf = pd.read_csv(yTC_csvpath + yTC_prefix + timestring + '.csv', header=None)\n",
    "\n",
    "    # pxt: x-coordinates of TRAPs, pyt: y-coordinates of TRAPs - size: [#points along a TRAP, #TRAPs]\n",
    "    # Transpose directly to attain the TRAP number along the index and point numbers as columns.\n",
    "    # coordinates with Nan indicate regions of the tensor lines that do not satisfy the desired attraction properties\n",
    "    pd_pxt_cdf = pd.read_csv(pxt_csvpath + pxt_prefix + timestring + '.csv', header=None).T\n",
    "    pd_pyt_cdf = pd.read_csv(pyt_csvpath + pyt_prefix + timestring + '.csv', header=None).T\n",
    "\n",
    "    # s1TC: attraction rate at trap cores - vector\n",
    "    pd_s1TC_cdf = pd.read_csv(s1TC_csvpath + s1TC_prefix + timestring + '.csv', header=None)\n",
    "    \n",
    "    # assert that coordinate arrays are of same shape\n",
    "    assert pd_xTC_cdf.shape==pd_yTC_cdf.shape, 'TRAP cores: different number of x- and y-coordinates'\n",
    "    assert pd_pxt_cdf.shape==pd_pyt_cdf.shape, 'TRAP curves: different number of x- and y-coordinates'\n",
    "\n",
    "    # assert that number of TRAP cores equals number of TRAP curves/tensor lines and number of attraction rates\n",
    "    assert pd_xTC_cdf.shape[0]==pd_pxt_cdf.shape[0], 'mismatch number of TRAP cores and curves'\n",
    "    assert pd_xTC_cdf.shape==pd_s1TC_cdf.shape, 'mismatch number of TRAP cores and number of attraction rates'\n",
    "    \n",
    "    # insert time column to make later retracing of individual TRAPs possible\n",
    "    pd_xTC_cdf.insert(0, 'time', timestring)\n",
    "    pd_yTC_cdf.insert(0, 'time', timestring)\n",
    "    pd_pxt_cdf.insert(0, 'time', timestring)\n",
    "    pd_pyt_cdf.insert(0, 'time', timestring)\n",
    "    pd_s1TC_cdf.insert(0, 'time', timestring)\n",
    "    \n",
    "    # concatenate current dataframes to the main one\n",
    "    pd_xTC_df = pd.concat([pd_xTC_df, pd_xTC_cdf])\n",
    "    pd_yTC_df = pd.concat([pd_yTC_df, pd_yTC_cdf])\n",
    "    pd_pxt_df = pd.concat([pd_pxt_df, pd_pxt_cdf])\n",
    "    pd_pyt_df = pd.concat([pd_pyt_df, pd_pyt_cdf])\n",
    "    pd_s1TC_df = pd.concat([pd_s1TC_df, pd_s1TC_cdf])\n",
    "    \n",
    "    \n",
    "# index is the number of a TRAP at the given timestep\n",
    "# together with the time column this allows for a unique identification of a TRAP and for later retracing\n",
    "pd_xTC_df.index.name = 'TRAP_ID'\n",
    "pd_yTC_df.index.name = 'TRAP_ID'\n",
    "pd_pxt_df.index.name = 'TRAP_ID'\n",
    "pd_pyt_df.index.name = 'TRAP_ID'\n",
    "pd_s1TC_df.index.name = 'TRAP_ID'\n",
    "\n",
    "stop_timer = time.perf_counter()\n",
    "print(f'task time: {stop_timer - start_timer:0.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_xTC_df.to_csv('export_csv_TRAPS/' + vel_product_short + '/' + year + '/pd_xTC_' + year + '_df.csv', header=True, index=True)\n",
    "pd_yTC_df.to_csv('export_csv_TRAPS/' + vel_product_short + '/' + year + '/pd_yTC_' + year + '_df.csv', header=True, index=True)\n",
    "pd_pxt_df.to_csv('export_csv_TRAPS/' + vel_product_short + '/' + year + '/pd_pxt_' + year + '_df.csv', header=True, index=True)\n",
    "pd_pyt_df.to_csv('export_csv_TRAPS/' + vel_product_short + '/' + year + '/pd_pyt_' + year + '_df.csv', header=True, index=True)\n",
    "pd_s1TC_df.to_csv('export_csv_TRAPS/' + vel_product_short + '/' + year + '/pd_s1TC_' + year + '_df.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the computation time for the entire script\n",
    "stop_script_timer = time.perf_counter()\n",
    "print(f'overall computation time: {stop_script_timer - start_script_timer:0.3f} seconds (' + year + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/tamsanh/a658c1b29b8cba7d782a8b3aed685a24\n",
    "\n",
    "framerate = 4410\n",
    "play_time_seconds = 1\n",
    "\n",
    "t = np.linspace(0, play_time_seconds, framerate*play_time_seconds)\n",
    "# G-Dur\n",
    "#audio_data = np.sin(2*np.pi*391*t) + np.sin(2*np.pi*493*t) + np.sin(2*np.pi*587*t)\n",
    "# D-Dur\n",
    "audio_data = np.sin(2*np.pi*293*t) + np.sin(2*np.pi*369*t) + np.sin(2*np.pi*440*t)\n",
    "Audio(audio_data, rate=framerate, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
